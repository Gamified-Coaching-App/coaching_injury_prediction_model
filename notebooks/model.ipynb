{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class RunningDataset:\n",
    "    def __init__(self):\n",
    "        self.filename = 'day_approach_maskedID_timeseries.csv'\n",
    "        self.WINDOW_DAYS = 7\n",
    "        self.base_metrics = ['nr. sessions', 'total km', 'km Z3-4', 'km Z5-T1-T2', 'km sprinting', \n",
    "                             'strength training', 'hours alternative', 'perceived exertion', \n",
    "                             'perceived trainingSuccess', 'perceived recovery']\n",
    "        self.identifiers = ['Athlete ID', 'Date']\n",
    "        self.class_name = 'injury'\n",
    "        self.fixed_columns = ['Athlete ID', 'injury', 'Date']\n",
    "        self.data_types_metrics = [float] * len(self.base_metrics)\n",
    "        self.data_types_fixed_columns = [int] * len(self.identifiers)\n",
    "        self.data = pd.read_csv(self.filename)\n",
    "        self.data.columns = [f\"{col}.0\" if i < 10 else col for i, col in enumerate(self.data.columns)]\n",
    "        self.standard_scaler = StandardScaler()\n",
    "        self.min_max_scaler = MinMaxScaler()\n",
    "        self.split_data()\n",
    "\n",
    "    def split_data(self):\n",
    "        all_ids = self.data[self.identifiers[0]].unique()\n",
    "        train_ids = np.random.choice(all_ids, int(0.865 * len(all_ids)), replace=False)\n",
    "        test_ids = np.setdiff1d(all_ids, train_ids)\n",
    "        self.train = self.data[self.data[self.identifiers[0]].isin(train_ids)]\n",
    "        self.test = self.data[self.data[self.identifiers[0]].isin(test_ids)]\n",
    "\n",
    "    def long_form(self, df):\n",
    "        df_long = pd.wide_to_long(df, stubnames=self.base_metrics, i=self.fixed_columns, j='Offset', sep='.')\n",
    "        df_long.reset_index(inplace=True)\n",
    "        df_long[self.identifiers[1]] = df_long[self.identifiers[1]] - (self.WINDOW_DAYS - df_long['Offset'])\n",
    "        df_long.drop(columns='Offset', inplace=True)\n",
    "        df_long.drop_duplicates(subset=self.identifiers, keep='first', inplace=True)\n",
    "        return df_long\n",
    "    \n",
    "    def z_score_normalization(self, df):\n",
    "        for metric in self.base_metrics:\n",
    "            df[metric] = df.groupby([self.identifiers[0]])[metric].transform(\n",
    "                lambda x: self.standard_scaler.fit_transform(x.values.reshape(-1, 1)).flatten()\n",
    "            )\n",
    "        return df.reset_index(drop=True)\n",
    "    \n",
    "    def min_max_normalization(self, df):\n",
    "        for metric in self.base_metrics:\n",
    "            df[metric] = df.groupby([self.identifiers[0]])[metric].transform(\n",
    "                lambda x: self.min_max_scaler.fit_transform(x.values.reshape(-1, 1)).flatten()\n",
    "            )\n",
    "        return df.reset_index(drop=True)\n",
    "    \n",
    "    def wide_form(self, df_long, days):\n",
    "        df_long = df_long.groupby(self.identifiers[0], as_index=False).apply(self.fill_missing_dates).reset_index(drop=True)\n",
    "        df_long.sort_values(by=self.identifiers, inplace=True)\n",
    "        athlete_info = df_long[self.fixed_columns]\n",
    "        df_rolled = pd.DataFrame(index=athlete_info.index).join(athlete_info)\n",
    "        for day in range(days):\n",
    "            shifted = df_long.groupby(self.identifiers[0])[self.base_metrics].shift(day).add_suffix(f'.{days - 1 - day}')\n",
    "            df_rolled = df_rolled.join(shifted)\n",
    "        metric_columns = [f'{metric}.{day}' for day in range(days) for metric in self.base_metrics]\n",
    "        df_rolled = df_rolled[metric_columns + self.fixed_columns]\n",
    "        df_rolled.dropna(inplace=True)\n",
    "        df_rolled.reset_index(drop=True, inplace=True)\n",
    "        df_rolled.sort_values(by=self.identifiers, inplace=True)\n",
    "        df_rolled[self.identifiers[1]] = df_rolled[self.identifiers[1]] + 1\n",
    "        df_rolled = df_rolled.sort_values(by=self.identifiers).reset_index(drop=True)\n",
    "        df_rolled = df_rolled.astype(dict(zip(df_rolled.columns, self.data_types_metrics * days + self.data_types_fixed_columns)))\n",
    "        return df_rolled\n",
    "    \n",
    "    def fill_missing_dates(self, group):\n",
    "        min_date = group[self.identifiers[1]].min()\n",
    "        max_date = group[self.identifiers[1]].max()\n",
    "        int_range = range(min_date, max_date + 1)\n",
    "        group = group.set_index(self.identifiers[1]).reindex(int_range).rename_axis(self.identifiers[1]).reset_index()\n",
    "        group[self.identifiers[0]] = group[self.identifiers[0]].ffill()\n",
    "        return group\n",
    "\n",
    "    def normalise(self, dataset):\n",
    "        long = self.long_form(dataset)\n",
    "        long = self.z_score_normalization(long)\n",
    "        long = self.min_max_normalization(long)\n",
    "        return self.wide_form(long, 7)\n",
    "    \n",
    "    def multi_resample(self, dataset):\n",
    "        # Step 1: Balanced Sampling\n",
    "        balanced_data = self.balanced_sampling(dataset)\n",
    "        # Step 2: Unbalanced Sampling\n",
    "        unbalanced_data = self.unbalanced_sampling(balanced_data, 650, 0.136)\n",
    "        # Step 3: Synthetic Sampling\n",
    "        X_resampled, y_resampled = self.synthetic_sampling(unbalanced_data, 0.136)\n",
    "        \n",
    "        return X_resampled, y_resampled\n",
    "\n",
    "    def balanced_sampling(self, data):\n",
    "        groups = data.groupby('Athlete ID')\n",
    "        balanced_data = []\n",
    "\n",
    "        for _, group in groups:\n",
    "            injured = group[group[self.class_name] == 1]\n",
    "            uninjured = group[group[self.class_name] == 0]\n",
    "\n",
    "            n_samples = max(len(injured), len(uninjured))  # Change to max to allow oversampling the smaller group\n",
    "            injured_sample = injured.sample(n_samples, replace=True)  # Allow replacement to enable oversampling\n",
    "            uninjured_sample = uninjured.sample(n_samples, replace=False)  # Ensure both classes are balanced\n",
    "\n",
    "            balanced_data.append(injured_sample)\n",
    "            balanced_data.append(uninjured_sample)\n",
    "\n",
    "        return pd.concat(balanced_data)\n",
    "\n",
    "    def unbalanced_sampling(self, balanced_data, injury_count, sampling_ratio):\n",
    "        injured = balanced_data[balanced_data['injury'] == 1]\n",
    "        uninjured = balanced_data[balanced_data['injury'] == 0]\n",
    "\n",
    "        num_injured = injury_count\n",
    "        num_uninjured = int(num_injured / sampling_ratio)\n",
    "\n",
    "        injured_sample = injured.sample(num_injured, replace=False)\n",
    "        uninjured_sample = uninjured.sample(num_uninjured, replace=False)\n",
    "\n",
    "        return pd.concat([injured_sample, uninjured_sample])\n",
    "\n",
    "    def synthetic_sampling(self, data, sampling_rate=1):\n",
    "        X = data.drop(columns=self.identifiers)\n",
    "        y = data[self.class_name]\n",
    "\n",
    "        # First, apply Tomek Links to remove majority class samples in Tomek pairs\n",
    "        tl = TomekLinks()\n",
    "        X_cleaned, y_cleaned = tl.fit_resample(X, y)\n",
    "\n",
    "        # Then, use SMOTE to oversample the minority class based on the new class distribution\n",
    "        smote = SMOTE(sampling_strategy=sampling_rate, random_state=42)  \n",
    "        X_resampled, y_resampled = smote.fit_resample(X_cleaned, y_cleaned)\n",
    "\n",
    "        return pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled)\n",
    "    \n",
    "    def transform_3d(self, data): \n",
    "        ids = data['Athlete ID']\n",
    "        labels = data[self.class_name]\n",
    "        dates = data['Date']\n",
    "        features = data.loc[:,~data.columns.isin(self.fixed_columns)]  # Adjust this slice depending on where your label columns are\n",
    "\n",
    "        # Check if the number of feature columns is exactly 70\n",
    "        if features.shape[1] != 70:\n",
    "            raise ValueError(\"The number of feature columns is not 70\")\n",
    "\n",
    "        # Reshape the feature array to a tensor that rearranges the data as specified\n",
    "        # This will create a tensor of shape (N, 10, 7) where each row in the 10x7 matrix\n",
    "        # is filled by taking every 10th element starting from indices 0, 1, 2,..., 9\n",
    "        reshaped_features = np.zeros((len(features), 10, 7))\n",
    "        for i in range(10):  # For each row in the 10x7 matrix\n",
    "            reshaped_features[:, i, :] = features.iloc[:, i::10].to_numpy()[:,:7]\n",
    "\n",
    "        # Initialize a new numpy array with an extra column for zeros\n",
    "        expanded_features = np.zeros((reshaped_features.shape[0], 10, 8))\n",
    "\n",
    "        # Copy the original features into the new array leaving the last column as zeros\n",
    "        expanded_features[:, :, 1:] = reshaped_features\n",
    "        \n",
    "        return ids, labels, dates, expanded_features\n",
    "\n",
    "    def compute_gasf(series):\n",
    "        \"\"\" Compute the Gramian Angular Summation Field (GASF) for a time series. \"\"\"\n",
    "        # Map the normalized series to an angular representation\n",
    "        phi = np.arccos(series)\n",
    "        \n",
    "        # Create the GASF matrix\n",
    "        gasf = np.array([np.cos(phi_i + phi_j) for phi_i in phi for phi_j in phi]).reshape(len(phi), len(phi))\n",
    "        \n",
    "        return gasf\n",
    "\n",
    "    def image_encoding(self, data):\n",
    "        \"\"\" Transform each 8-element array in a 40000 x 10 x 8 dataset to an 8x8 GASF. \"\"\"\n",
    "        n_samples, n_rows, n_cols = data.shape\n",
    "        if n_cols != 8:\n",
    "            raise ValueError(\"Each inner array must have 8 elements.\")\n",
    "        \n",
    "        # Initialize an empty array to store the GASF matrices\n",
    "        gasf_matrices = np.empty((n_samples, n_rows, n_cols, n_cols))\n",
    "        \n",
    "        # Compute the GASF for each 8-element array\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_rows):\n",
    "                gasf_matrices[i, j] = self.compute_gasf(data[i, j])\n",
    "        \n",
    "        return gasf_matrices\n",
    "\n",
    "    \n",
    "    def preprocess(self):\n",
    "        self.split_data(self.data)\n",
    "        self.train = self.normalise(self.train)\n",
    "        self.test = self.normalise(self.test)\n",
    "        X_train, y_train = self.multi_resample(self.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [nr. sessions.0, total km.0, km Z3-4.0, km Z5-T1-T2.0, km sprinting.0, strength training.0, hours alternative.0, perceived exertion.0, perceived trainingSuccess.0, perceived recovery.0, nr. sessions.1, total km.1, km Z3-4.1, km Z5-T1-T2.1, km sprinting.1, strength training.1, hours alternative.1, perceived exertion.1, perceived trainingSuccess.1, perceived recovery.1, nr. sessions.2, total km.2, km Z3-4.2, km Z5-T1-T2.2, km sprinting.2, strength training.2, hours alternative.2, perceived exertion.2, perceived trainingSuccess.2, perceived recovery.2, nr. sessions.3, total km.3, km Z3-4.3, km Z5-T1-T2.3, km sprinting.3, strength training.3, hours alternative.3, perceived exertion.3, perceived trainingSuccess.3, perceived recovery.3, nr. sessions.4, total km.4, km Z3-4.4, km Z5-T1-T2.4, km sprinting.4, strength training.4, hours alternative.4, perceived exertion.4, perceived trainingSuccess.4, perceived recovery.4, nr. sessions.5, total km.5, km Z3-4.5, km Z5-T1-T2.5, km sprinting.5, strength training.5, hours alternative.5, perceived exertion.5, perceived trainingSuccess.5, perceived recovery.5, nr. sessions.6, total km.6, km Z3-4.6, km Z5-T1-T2.6, km sprinting.6, strength training.6, hours alternative.6, perceived exertion.6, perceived trainingSuccess.6, perceived recovery.6, Athlete ID, injury, Date]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "data = RunningDataset()\n",
    "filtered_data = data.data[data.data['Athlete ID'] == 11]\n",
    "print(filtered_data[filtered_data['injury'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42766, 10, 8)  first row: [ 0.   5.8  0.   0.   0.   0.  16.4  0. ]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr. sessions.0</th>\n",
       "      <th>total km.0</th>\n",
       "      <th>km Z3-4.0</th>\n",
       "      <th>km Z5-T1-T2.0</th>\n",
       "      <th>km sprinting.0</th>\n",
       "      <th>strength training.0</th>\n",
       "      <th>hours alternative.0</th>\n",
       "      <th>perceived exertion.0</th>\n",
       "      <th>perceived trainingSuccess.0</th>\n",
       "      <th>perceived recovery.0</th>\n",
       "      <th>...</th>\n",
       "      <th>km Z5-T1-T2.6</th>\n",
       "      <th>km sprinting.6</th>\n",
       "      <th>strength training.6</th>\n",
       "      <th>hours alternative.6</th>\n",
       "      <th>perceived exertion.6</th>\n",
       "      <th>perceived trainingSuccess.6</th>\n",
       "      <th>perceived recovery.6</th>\n",
       "      <th>Athlete ID</th>\n",
       "      <th>injury</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr. sessions.0  total km.0  km Z3-4.0  km Z5-T1-T2.0  km sprinting.0  \\\n",
       "0             1.0         5.8        0.0            0.6             1.2   \n",
       "1             0.0         0.0        0.0            0.0             0.0   \n",
       "2             1.0         0.0        0.0            0.0             0.0   \n",
       "3             0.0         0.0        0.0            0.0             0.0   \n",
       "4             1.0         0.0        0.0            0.0             0.0   \n",
       "\n",
       "   strength training.0  hours alternative.0  perceived exertion.0  \\\n",
       "0                  0.0                 0.00                  0.11   \n",
       "1                  0.0                 0.00                 -0.01   \n",
       "2                  1.0                 0.00                  0.10   \n",
       "3                  0.0                 0.00                 -0.01   \n",
       "4                  0.0                 1.08                  0.08   \n",
       "\n",
       "   perceived trainingSuccess.0  perceived recovery.0  ...  km Z5-T1-T2.6  \\\n",
       "0                         0.00                  0.18  ...            0.0   \n",
       "1                        -0.01                 -0.01  ...            0.5   \n",
       "2                         0.00                  0.17  ...            0.0   \n",
       "3                        -0.01                 -0.01  ...            0.0   \n",
       "4                         0.00                  0.18  ...            0.0   \n",
       "\n",
       "   km sprinting.6  strength training.6  hours alternative.6  \\\n",
       "0             0.0                  0.0                  1.0   \n",
       "1             1.2                  0.0                  0.0   \n",
       "2             0.0                  0.0                  0.0   \n",
       "3             0.0                  1.0                  0.0   \n",
       "4             0.0                  0.0                  0.0   \n",
       "\n",
       "   perceived exertion.6  perceived trainingSuccess.6  perceived recovery.6  \\\n",
       "0                  0.10                         0.00                  0.15   \n",
       "1                  0.10                         0.00                  0.17   \n",
       "2                 -0.01                        -0.01                 -0.01   \n",
       "3                  0.10                         0.00                  0.17   \n",
       "4                  0.11                         0.00                  0.17   \n",
       "\n",
       "   Athlete ID  injury  Date  \n",
       "0           0       0     0  \n",
       "1           0       0     1  \n",
       "2           0       0     2  \n",
       "3           0       0     3  \n",
       "4           0       0     4  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
